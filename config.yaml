model:
  base_model: sentence-transformers/msmarco-MiniLM-L6-v3

training:
  batch_size: 32
  epochs: 5
  learning_rate: 2e-5
  margin: 1.0
  freeze_encoder: true
  save_dir: models/

dataset:
  cache_dir: .hf_cache
